<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Internet Res</journal-id><journal-id journal-id-type="iso-abbrev">J. Med. Internet Res</journal-id><journal-id journal-id-type="publisher-id">JMIR</journal-id><journal-title-group><journal-title>Journal of Medical Internet Research</journal-title></journal-title-group><issn pub-type="ppub">1439-4456</issn><issn pub-type="epub">1438-8871</issn><publisher><publisher-name>Gunther Eysenbach</publisher-name><publisher-loc>JMIR Publications Inc., Toronto, Canada</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">23160103</article-id><article-id pub-id-type="pmc">3510731</article-id><article-id pub-id-type="publisher-id">v14i6e157</article-id><article-id pub-id-type="doi">10.2196/jmir.2186</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject></subj-group></article-categories><title-group><article-title>How Should Debriefing Be Undertaken in Web-Based Studies? Findings From a Randomized Controlled Trial</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Eysenbach</surname><given-names>Gunther</given-names></name></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Whitehead</surname><given-names>Lisa</given-names></name></contrib><contrib contrib-type="reviewer"><name><surname>Lim Choi Keung</surname><given-names>Sarah</given-names></name></contrib></contrib-group><contrib-group><contrib id="contrib1" contrib-type="author" corresp="yes"><name><surname>McCambridge</surname><given-names>Jim</given-names></name><xref ref-type="aff" rid="aff1">1</xref><address><institution>Department of Social &#x00026; Environmental Health Research</institution><institution>Faculty of Public Health &#x00026; Policy</institution><institution>LSHTM, London</institution><addr-line>LSHTM</addr-line><addr-line>15-17 Tavistock Place</addr-line><addr-line>London, WC1H 9HS</addr-line><country>United Kingdom</country><phone>44 20 7927 2945</phone><fax>44 20 7927 2945</fax><email>Jim.McCambridge@lshtm.ac.uk</email></address></contrib><contrib id="contrib2" contrib-type="author"><name><surname>Kypri</surname><given-names>Kypros</given-names></name><xref ref-type="aff" rid="aff2">2</xref></contrib><contrib id="contrib3" contrib-type="author"><name><surname>Wilson</surname><given-names>Amanda</given-names></name><xref ref-type="aff" rid="aff2">2</xref></contrib></contrib-group><aff id="aff1" rid="aff1"><sup>1</sup><institution>Department of Social &#x00026; Environmental Health Research</institution><institution>Faculty of Public Health &#x00026; Policy</institution><institution>LSHTM, London</institution><addr-line>London</addr-line><country>United Kingdom</country></aff><aff id="aff2" rid="aff2"><sup>2</sup><institution>Centre for Clinical Epidemiology &#x00026; Biostatistics</institution><institution>School of Medicine and Public Health</institution><institution>University of Newcastle</institution><addr-line>Callaghan NSW 2308</addr-line><country>Australia</country></aff><pub-date pub-type="collection"><season>Nov-Dec</season><year>2012</year></pub-date><pub-date pub-type="epub"><day>16</day><month>11</month><year>2012</year></pub-date><volume>14</volume><issue>6</issue><elocation-id>e157</elocation-id><history><date date-type="received"><day>26</day><month>5</month><year>2012</year></date><date date-type="rev-request"><day>27</day><month>6</month><year>2012</year></date><date date-type="rev-recd"><day>18</day><month>7</month><year>2012</year></date><date date-type="accepted"><day>30</day><month>7</month><year>2012</year></date></history><permissions><copyright-statement>&#x000a9;Jim McCambridge, Kypros Kypri, Amanda Wilson. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 16.11.2012. </copyright-statement><copyright-year>2012</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0/"><license-p><!--CREATIVE COMMONS-->This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0/">http://creativecommons.org/licenses/by/2.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/,">http://www.jmir.org/,</ext-link> as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:type="simple" xlink:href="http://www.jmir.org/2012/6/e157/"/><abstract><sec sec-type="Background"><title>Background</title><p>Internet research may raise older ethical issues in new forms or pose new issues. It has been recommended that debriefing information online be kept very short, with further information including study results made available if requested by participants. There are no empirical studies that compare possible alternative methods of debriefing in online studies.</p></sec><sec sec-type="Objective"><title>Objective</title><p>To undertake a randomized controlled trial evaluating how to implement the recommended approach by assessing the effects of two different approaches on accessing of additional information.</p></sec><sec sec-type="Methods"><title>Methods</title><p>All 11,943 participants in the Effects of Study Design and Allocation (ESDA) study, which employed deception, were randomly assigned to one of two methods of debriefing: Group A received the debriefing information in the body of an email with links to protocol and results pages; Group B was presented with these links after clicking on an initial link in the body of the email to view the debriefing information on a website. Outcomes assessed were the proportions clicking on the links to the protocol and results summary and the time spent on these pages by those accessing them.</p></sec><sec sec-type="Results"><title>Results</title><p>The group who were presented with no debriefing information in the body of the email and went to a website for this information (Group B) were approximately twice as likely to subsequently access the protocol and the results summary. These differences between the two groups were highly statistically significant. Although these differences are clear, the overall proportions accessing such information were low, and there were no differences in mean time spent reading these pages. Only one quarter of Group B actually accessed debriefing information.</p></sec><sec sec-type="Conclusions"><title>Conclusions</title><p>In circumstances where the uptake of fuller information on study design, methods, and findings is deemed important, debriefing information may be better provided via a link and not included in the body of an email. Doing so may, however, reduce the extent of receiving any debriefing information at all. There is a wider need for high quality empirical studies to inform ethical evaluations.</p></sec><sec sec-type="Trial Registration"><title>Trial Registration</title><p>Australian New Zealand Clinical Trials Registry, ACTRN12610000846022 (http://www.anzctr.org.au/)</p></sec></abstract><kwd-group><kwd>ethics</kwd><kwd>debriefing</kwd><kwd>deception</kwd><kwd>online</kwd><kwd>web-based</kwd><kwd>randomised controlled trial</kwd><kwd>methodology</kwd></kwd-group></article-meta></front><body><sec><title>Introduction</title><p>Behavior change interventions for public health purposes, as with health care itself, are increasingly being delivered and evaluated using the Internet [<xref ref-type="bibr" rid="ref1">1</xref>-<xref ref-type="bibr" rid="ref3">3</xref>]. This development may pose existing ethical questions in new forms, or pose new questions [<xref ref-type="bibr" rid="ref4">4</xref>]. For example, it may be difficult to know whether research participants actually read study information and give genuinely informed consent. The adequacy of informed consent may also be difficult to assess in non-Internet studies [<xref ref-type="bibr" rid="ref5">5</xref>], and dedicated investigations typically find that recall of consent is poor and may benefit from intervention [<xref ref-type="bibr" rid="ref6">6</xref>]. Because of these challenges, ethical guidance for behavioral research on the Internet has been produced [<xref ref-type="bibr" rid="ref2">2</xref>,<xref ref-type="bibr" rid="ref7">7</xref>]. Among the recommendations are that debriefing information be kept very short, with further information including study results made available if requested by participants [<xref ref-type="bibr" rid="ref7">7</xref>]. We are unaware of any empirical studies that compare possible alternative methods of debriefing in online studies. Such data would assist evaluation of ethical issues relating to debriefing.</p><p>The Internet is also a useful vehicle for methodological research on participant behavior, partly by virtue of the direct access to large numbers of study participants it affords. Blinding is recommended by the Cochrane Collaboration [<xref ref-type="bibr" rid="ref8">8</xref>] and others as a means of constraining bias in intervention research. Social psychological research routinely uses deception for similar methodological reasons (for a review see [<xref ref-type="bibr" rid="ref9">9</xref>]), although the use of deception has not been studied very much in relation to health [<xref ref-type="bibr" rid="ref10">10</xref>]. Ethical guidance usually requires debriefing following deception [<xref ref-type="bibr" rid="ref11">11</xref>] though the content of methods of debriefing has been neither widely considered nor studied [<xref ref-type="bibr" rid="ref12">12</xref>]. Debriefing involves giving study information after the study has ended that would usually be provided prior to participation to permit informed consent. This is usually accompanied with a brief explanation of the rationale for the study design and where there is any potential for harm this can be explored.</p><p>This study is a randomized controlled trial evaluating how to implement the recommended approach to debriefing by assessing the effects of two different methods on participants&#x02019; accessing of additional information indicative of successful engagement with debriefing.</p></sec><sec sec-type="methods"><title>Methods</title><p>We have previously undertaken a methodological study, the ESDA trial, investigating the possible effects of study design and allocation on participant behavior in the context of a study appearing to investigate alcohol consumption [<xref ref-type="bibr" rid="ref13">13</xref>]. Almost 12,000 students from four universities in New Zealand participated and were randomized to one of three study conditions, which differed only in what the participants were told was the nature of the study and their role in it. One group believed they were participating in a cohort study, while the other two groups believed they were participants in the intervention and control groups respectively in a randomized controlled trial evaluating an alcohol education intervention, to which all three groups were given access [<xref ref-type="bibr" rid="ref13">13</xref>]. After the collection of one month outcome data, for the present study we further randomized all participants to two alternative forms of debriefing.</p><p>All ESDA participants were randomly allocated to either Group A or Group B. Randomization was computerized and stratified by university, so that there were not imbalances in allocations within any of the 4 participating universities. This and all other study procedures were fully automated and could not be subverted. Allocation was thus fully concealed. Both Groups received an email, sent out on September 22nd, 2011. The initial contents of the emails for both groups are provided in <xref ref-type="boxed-text" rid="box1">Textbox 1</xref>. We allowed 6 weeks for students to respond to the emails, terminating the study on November 11th, 2011. Group A received the debriefing information presented in <xref ref-type="boxed-text" rid="box2">Textbox 2</xref> in the body of the email, after the text provided in <xref ref-type="boxed-text" rid="box1">Textbox 1</xref>, with links to the protocol (on the journal website) and results pages (see <xref ref-type="boxed-text" rid="box3">Textbox 3</xref>) via [<xref ref-type="bibr" rid="ref14">14</xref>]. Group B received an email containing no debriefing information, with links to the protocol and results via [<xref ref-type="bibr" rid="ref15">15</xref>] where the basic debriefing information in <xref ref-type="boxed-text" rid="box2">Textbox 2</xref> was presented. Group B thus looked at the debriefing information after clicking on a link to the website rather than in the body of the email. All available trial outcome data comprised the proportions clicking on the links to the protocol and the results summary in both groups and the time spent on these pages among those accessing them. We are also able to report on the proportion of Group B accessing the debriefing information on the website and on the time spent reading this page. We tested differences between groups in chi-squared tests for the former and Kruskal-Wallis tests for the latter, for which we report medians. The latter statistical test was chosen in light of the observed gross non-normality with some participants spending very little time with the pages open and others spending more time reading. A non-parametric test was judged preferable to a parametric test to analyze this distribution.</p><boxed-text id="box1" position="float"><caption><title>Initial Email Contents for Both Groups.</title></caption><p>
<bold>Group A</bold>
</p><p>
<bold>Subject Line: Tertiary Student Health Project - Information for Participants</bold>
</p><p>&#x000a0;</p><p>
In 2010/11 you participated in an online survey about student drinking. Thank you for taking part. As promised, we would like to provide you with some more information about this study which is available below.</p><p>
This is the last email you will receive about this study. Our database containing participant email addresses will now be deleted.</p><p>
The iPads were won by students from University of Otago and Victoria University Wellington.</p><p>&#x000a0;</p><p>
<bold>Group B</bold>
</p><p>
<bold>Subject Line: Tertiary Student Health Project - Information for Participants</bold>
</p><p>&#x000a0;</p><p>
In 2010/11 you participated in an online survey about student drinking. Thank you for taking part.</p><p>
As promised, we would like to provide you with some more information about this study which is available here.</p><p>
&#x0003c;LINK)</p><p>
This is the last email you will receive about this study. Our database containing participant email addresses will now be deleted.</p><p>
The iPads were won by students from University of Otago and Victoria University Wellington.</p><p>
If you experience problems with this link, please copy and paste the link into a new window.</p></boxed-text><boxed-text id="box2" position="float"><caption><title>Basic Debriefing Text in Body of Email for Group a Only, Accessed Via Link for Group B.</title></caption><p>The study randomly assigned people to one of three groups (A, B or C). Group A was told they were completing two surveys. Group B was told they were in a Control Group in a randomised controlled trial evaluating brief alcohol education. Group C was told they were in an Intervention Group in the same trial. In fact, all participants received the same information about alcohol. Apart from what they were told about the nature of the study, there were no differences between the groups. Any differences in reported alcohol consumption were expected to be due to the type of research study people thought they were involved in.</p><p>
It is unknown whether people change their drinking behaviour, or their reporting of it, according to what type of study they are in. This was worth knowing because it has implications for how research on drinking and other behaviours is conducted and interpreted. We did not find any differences between any of the groups.</p><p>
As stated in the Information Sheet, no individually identifying information has been collected and your anonymity has been preserved throughout the study.</p></boxed-text><boxed-text id="box3" position="float"><caption><title>Results summary (available to both Group A and Group B).</title></caption><p>In this study we tested two hypotheses:</p><p>
That knowledge of participation in a randomised controlled trial in comparison to a cohort (ie, before and after surveys) study alone will reduce drinking after 1 month. This was tested by comparing Group A versus Groups B and C together.</p><p>
That knowledge of allocation to an intervention condition in comparison to a control condition in a randomised controlled trial will reduce drinking after 1 month. This was tested by comparing Group B versus Group C.</p><p>
Both hypotheses were rejected, as no differences were found between Groups A, B and C. This means the type of study people believed they were in did not influence changes in their drinking behaviour or their reporting of it.</p><p>
We interpreted the implications of each of the findings for the two hypotheses differently because of the way this study was conducted. In relation to hypothesis 1, it may be worth generating a stronger sense of being in a randomised controlled trial in a future study. We do not believe hypothesis 2 needs further testing.</p></boxed-text></sec><sec sec-type="results"><title>Results</title><p>The CONSORT flowchart summarizing the study design and numbers included in the analyses is presented in <xref ref-type="fig" rid="figure1">Figure 1</xref>.</p><p>Group B was approximately twice as likely to have clicked on the protocol and results links, although the proportion doing so was less than 10% in each case (see <xref ref-type="table" rid="table1">Table 1</xref>). Group B was not likely to spend any more time reading this material. Approximately one quarter of this group visited the debrief page (see <xref ref-type="table" rid="table1">Table 1</xref>) and thus accessed any debriefing information at all, however, and we had no capacity to measure the extent of any reading of the debriefing information provided in the body of the email to Group A. Approximately one third of those who visited the debriefing page in Group B subsequently clicked on the link for results, and approximately one quarter did so for the protocol (see <xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1</label><caption><p>All outcome data.</p></caption><table frame="hsides" rules="groups" width="596" border="1" cellpadding="7" cellspacing="0"><col width="155" span="1"/><col width="203" span="1"/><col width="90" span="1"/><col width="90" span="1"/><thead><tr valign="top"><td colspan="2" rowspan="1">
<break/>
</td><td rowspan="1" colspan="1">Group A <break/>
(N = 6051)</td><td rowspan="1" colspan="1">Group B <break/>
(N = 5892)</td></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">
<bold>Clicked on Results link</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">247 (4.1%)<sup>a</sup>
</td><td rowspan="1" colspan="1">515 (8.7%)<sup>a</sup>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Median time in seconds (interquartile range)</td><td rowspan="1" colspan="1">25.0 (37.2)<sup>b</sup>
</td><td rowspan="1" colspan="1">25.3 (35.8)<sup>b</sup>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<bold>Clicked on Protocol link</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">202 (3.3%)<sup>a</sup>
</td><td rowspan="1" colspan="1">362 (6.1%)<sup>a</sup>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Median time in seconds (interquartile range)</td><td rowspan="1" colspan="1">3.5 (5.4)<sup>c</sup>
</td><td rowspan="1" colspan="1">3.6 (3.9)<sup>c</sup>
</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<bold>Visited Debrief page</bold>
</td><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">
<sup>d</sup>
</td><td rowspan="1" colspan="1">1427 (24.2%)</td></tr><tr valign="top"><td rowspan="1" colspan="1">
<break/>
</td><td rowspan="1" colspan="1">Median time in seconds (interquartile range)</td><td rowspan="1" colspan="1">
<sup>d</sup>
</td><td rowspan="1" colspan="1">36.1 (49.2)</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><p>
<sup>a </sup>
<italic>P</italic> values for differences between groups in chi-squared tests are all &#x0003c;0.001.</p></fn><fn id="table1fn2"><p>
<sup>b </sup>
<italic>P</italic> value for difference between groups from Kruskal-Wallis test = 0.7419.</p></fn><fn id="table1fn3"><p>
<sup>c </sup>
<italic>P</italic> value for difference between groups from Kruskal-Wallis test = 0.9450.</p></fn><fn id="table1fn4"><p>
<sup>d</sup> Not applicable to group A.</p></fn></table-wrap-foot></table-wrap><fig id="figure1" position="float"><label>Figure 1</label><caption><p>CONSORT flowchart.</p></caption><graphic xlink:href="jmir_v14i6e157_fig1"/></fig></sec><sec sec-type="discussion"><title>Discussion</title><p>There are two main sets of findings to consider. First, the between-group differences in the trial demonstrate that providing a link to basic debriefing information (rather than doing so within the body of an email message) approximately doubles the probability that participants will access further debriefing information by clicking on follow-on links. Secondly, the low overall levels of accessing this further information warrant consideration as does the low level of receipt of any debriefing information provided on a website (for Group B) rather than in the body of an email (as for Group A). The robustness of these findings is considered prior to assessment of their ethical and methodological implications.</p><p>The messages were all delivered to the email addresses of students held by the universities and via which students participated in the ESDA trial. In the CONSORT flowchart (see <xref ref-type="fig" rid="figure1">Figure 1</xref>), we have defined intervention receipt as dispatch of email. We assume that almost all were received and almost all were opened; however, we have no confirmatory data. Some students may have ignored the messages or were no longer using their university email address. We also cannot know for certain how much of the text presented in <xref ref-type="boxed-text" rid="box2">Textbox 2</xref> was actually read by those who opened the email (Group A) or visited the web page (Group B). Strictly speaking, our time spent on each page measure is of how long the page is open. It is likely that not all of this time was spent actually reading text if other distractions occurred; however, this should have been equally likely in both groups. A clear strength of the data reported here is that they are not reliant on self-report and subject to reporting biases, as they are objectively ascertained, both in relation to whether links were clicked and how long the pages were open. We did not measure email reading time, simply because we could not. One-time-only links to web pages were provided to ensure that participants were not counted twice.</p><p>It is possible that many more participants read at least some of the debriefing information in the Group A email and were satisfied with this, or otherwise decided that they did not want further information. To maximize the proportion of all participants having at least some debriefing information (for example, where moral accountability to the research participants is deemed most important [<xref ref-type="bibr" rid="ref12">12</xref>]), putting the information in the body of the email, as was done with Group A, might be preferable. Alternatively, a key purpose of debriefing is to discover and act upon any harms identified. The reactions of those who have been subjected to any form of deception in research are important to consider in ethical evaluations. For example, according to the British Psychological Society, &#x0201c;If this led to discomfort, anger or objections from the participants then the deception was inappropriate&#x0201d;[<xref ref-type="bibr" rid="ref11">11</xref>]. This was our primary research interest and why we believe that our outcome measures were well chosen: If research participants have concerns raised by online debriefing information, accessing further information is likely to be the first step in addressing these concerns, if it is made easily available. Where the uptake of more detailed information on study design, methods, and findings is deemed important, as may often be the case in studies involving deception, it appears that basic debriefing information could be better provided via a link and not included in the body of an email.</p><p>The low levels of access of the basic debriefing information in Group B remain, however, a matter of substantial concern, and they restrict the confidence that one may draw from the effects favoring Group B. Approximately three-quarters of these participants have received no debriefing information at all, and this appears to be a much bigger problem than we would have expected. If debriefing is worth doing, then it should be done as well as possible, in line with the motivating aims of the present study. This is true even in the absence of harms as they are usually conceived, in order to provide moral accountability for the infringement of the right to informed consent [<xref ref-type="bibr" rid="ref12">12</xref>]. These considerations direct our attention to the initial content of the original emails, shown in <xref ref-type="boxed-text" rid="box1">Textbox 1</xref>. It may be worth exploring alterations to this brief text, for example making known the absence of informed consent, in ways specifically designed to encourage the uptake of debriefing information.</p><p>In this particular study we chose not to elicit feedback as we have done in other studies because participant willingness to articulate concerns may be compromised if the vehicle provided is to communicate with the investigators. Instead, we checked with the Ethics Committee and with the universities involved and confirmed that they had received no complaints from students concerning any aspect of the research. It is therefore not so straightforward to put the two sets of findings together and determine the most appropriate course of action on debriefing. There is merit in further investigating the uptake rates of any debriefing information observed here for Group B, which have the advantage of reliable measurement. If the present findings are confirmed, on balance, we would judge these uptake rates to be unacceptably low and may prefer instead to include the debriefing information in the body of the email, but we have no means of knowing to what extent there is any engagement with information provided there. Time spent reading the protocol was low. It appears it was largely inspected for a few seconds and then the page closed. The results summary was designed to be brief and can be fully read in around the median time spent with the page open. We cannot know, however, how deeply this information was processed or whether the issues involved were more than superficially considered. Longer reading time would be more encouraging in this regard.</p><p>Ethical scrutiny of our own practice is made stronger by the kind of data reported here. Study participants were not exposed to risks or harms beyond the infringement of their rights to informed consent, which we acknowledge is a profound harm in itself. Can we make any assumptions about those who did not read the debriefing information? We believe that we cannot, as it would seem unwise to consider either that they may be unconcerned about the infringement of their right to informed consent as research participants, or alternatively that they would be greatly concerned. There are few previous studies providing helpful data in this regard, though Fisher and Fyrberg [<xref ref-type="bibr" rid="ref9">9</xref>] identified approximately 70% of university student participants as having a basically utilitarian attitude to infringements of such rights in research and approximately 30% who may be offended, among whom a much smaller proportion were deeply offended. These harms need to be balanced against the research and hence the social value of the data obtained.</p><p>In our ethical deliberations on this type of research, we were concerned that debriefing itself may constitute a source of harm by revealing an infringement of rights not previously known. The data in the present study are helpful to ongoing consideration of whether debriefing should be undertaken, as well as how. We found no evidence in this particular study that debriefing itself may be harmful and therefore no reason to discontinue it, although consideration of the cumulative impact of such debriefing, in populations such as students who are regularly invited to participate in research, as well as the use of deception in research more broadly, is warranted. For example, it is entirely possible that those who have been debriefed may be more cautious about participating in future research studies, which would diminish the value of the data obtained in those studies. This type of harm is both important and challenging to evaluate. Empirical data are of course no substitute for ethical reflection; however, they can also undoubtedly enrich it. The paucity of empirical data in relation to ethical decision-making has previously been commented upon [<xref ref-type="bibr" rid="ref16">16</xref>]. We very much agree there is a wider need for high quality empirical studies, using experimental data in particular, to inform ethical evaluations of future methodological developments, online and elsewhere.</p></sec></body><back><ack><p> The research was funded via an Australian Research Council Discovery Project Grant (DP1093809) and by a Wellcome Trust Research Career Development award in Basic Biomedical Science (WT086516MA) to the first author. The funders had no role in the conduct of the research or in publication decision-making. Programming of the web instrument was performed by Dean Pung. We are grateful to the University of Waikato, Victoria University Wellington, University of Canterbury, and University of Otago for facilitating the study.</p></ack><fn-group><fn fn-type="conflict"><p>None declared.</p></fn></fn-group><ref-list><ref id="ref1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitehead</surname><given-names>LC</given-names></name></person-group><article-title>Methodological and ethical issues in Internet-mediated research in the field of health: an integrated review of the literature</article-title><source>Soc Sci Med</source><year>2007</year><month>8</month><volume>65</volume><issue>4</issue><fpage>782</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.socscimed.2007.03.005</pub-id><pub-id pub-id-type="medline">17512105</pub-id><pub-id pub-id-type="pii">S0277-9536(07)00118-9</pub-id><pub-id pub-id-type="pmid">17512105</pub-id></element-citation></ref><ref id="ref2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barchard</surname><given-names>KA</given-names></name><name><surname>Williams</surname><given-names>J</given-names></name></person-group><article-title>Practical advice for conducting ethical online experiments and questionnaires for United States psychologists</article-title><source>Behav Res Methods</source><year>2008</year><month>11</month><volume>40</volume><issue>4</issue><fpage>1111</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.3758/BRM.40.4.1111</pub-id><pub-id pub-id-type="medline">19001403</pub-id><pub-id pub-id-type="pii">40/4/1111</pub-id><pub-id pub-id-type="pmid">19001403</pub-id></element-citation></ref><ref id="ref3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharkey</surname><given-names>S</given-names></name><name><surname>Jones</surname><given-names>R</given-names></name><name><surname>Smithson</surname><given-names>J</given-names></name><name><surname>Hewis</surname><given-names>E</given-names></name><name><surname>Emmens</surname><given-names>T</given-names></name><name><surname>Ford</surname><given-names>T</given-names></name><name><surname>Owens</surname><given-names>C</given-names></name></person-group><article-title>Ethical practice in internet research involving vulnerable people: lessons from a self-harm discussion forum study (SharpTalk)</article-title><source>J Med Ethics</source><year>2011</year><month>12</month><volume>37</volume><issue>12</issue><fpage>752</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1136/medethics-2011-100080</pub-id><pub-id pub-id-type="medline">21947802</pub-id><pub-id pub-id-type="pii">medethics-2011-100080</pub-id><pub-id pub-id-type="pmid">21947802</pub-id></element-citation></ref><ref id="ref4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>LA</given-names></name><name><surname>Black</surname><given-names>E</given-names></name><name><surname>Duff</surname><given-names>WP</given-names></name><name><surname>Paradise Black</surname><given-names>N</given-names></name><name><surname>Saliba</surname><given-names>H</given-names></name><name><surname>Dawson</surname><given-names>K</given-names></name></person-group><article-title>Protected health information on social networking sites: ethical and legal considerations</article-title><source>J Med Internet Res</source><year>2011</year><volume>13</volume><issue>1</issue><fpage>e8</fpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.jmir.org/2011/1/e8/"/></comment><pub-id pub-id-type="doi">10.2196/jmir.1590</pub-id><pub-id pub-id-type="medline">21247862</pub-id><pub-id pub-id-type="pii">v13i1e8</pub-id><pub-id pub-id-type="pmcid">PMC3221358</pub-id><pub-id pub-id-type="pmid">21247862</pub-id></element-citation></ref><ref id="ref5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varnhagen</surname><given-names>CK</given-names></name><name><surname>Gushta</surname><given-names>M</given-names></name><name><surname>Daniels</surname><given-names>J</given-names></name><name><surname>Peters</surname><given-names>TC</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Law</surname><given-names>D</given-names></name><name><surname>Hirsch</surname><given-names>R</given-names></name><name><surname>Takach</surname><given-names>BS</given-names></name><name><surname>Johnson</surname><given-names>T</given-names></name></person-group><article-title>How informed is online informed consent?</article-title><source>Ethics Behav</source><year>2005</year><volume>15</volume><issue>1</issue><fpage>37</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1207/s15327019eb1501_3</pub-id><pub-id pub-id-type="medline">16127857</pub-id><pub-id pub-id-type="pmid">16127857</pub-id></element-citation></ref><ref id="ref6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Festinger</surname><given-names>DS</given-names></name><name><surname>Marlowe</surname><given-names>DB</given-names></name><name><surname>Croft</surname><given-names>JR</given-names></name><name><surname>Dugosh</surname><given-names>KL</given-names></name><name><surname>Arabia</surname><given-names>PL</given-names></name><name><surname>Benasutti</surname><given-names>KM</given-names></name></person-group><article-title>Monetary incentives improve recall of research consent information: it pays to remember</article-title><source>Exp Clin Psychopharmacol</source><year>2009</year><month>4</month><volume>17</volume><issue>2</issue><fpage>99</fpage><lpage>104</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://europepmc.org/abstract/MED/19331486"/></comment><pub-id pub-id-type="doi">10.1037/a0015421</pub-id><pub-id pub-id-type="medline">19331486</pub-id><pub-id pub-id-type="pii">2009-04252-008</pub-id><pub-id pub-id-type="pmcid">PMC3218798</pub-id><pub-id pub-id-type="pmid">19331486</pub-id></element-citation></ref><ref id="ref7"><label>7</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>British Psychological Society</collab></person-group><source>Report of the Working Party on Conducting Reseach on the Internet: Guidelines for ethical practice in psychological research online</source><year>2007</year><date-in-citation>2012-11-14</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="http://www.bps.org.uk/sites/default/files/documents/conducting_research_on_the_internet-guidelines_for_ethical_practice_in_psychological_research_online.pdf">http://www.bps.org.uk/sites/default/files/documents/conducting_research_on_the_internet-guidelines_for_ethical_practice_in_psychological_research_online.pdf</ext-link></comment><ext-link ext-link-type="webcite" xlink:href="6CAuDJq6I"/></element-citation></ref><ref id="ref8"><label>8</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Higgins</surname><given-names>JPT</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Higgins</surname><given-names>JPT</given-names></name><name><surname>Green</surname><given-names>S</given-names></name></person-group><article-title>Chapter 8: Assessing risk of bias in included studies</article-title><source>Cochrane handbook for systematic reviews of interventions</source><year>2008</year><publisher-loc>Chichester, England</publisher-loc><publisher-name>Wiley-Blackwell</publisher-name></element-citation></ref><ref id="ref9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>B</given-names></name><name><surname>Fyrberg</surname><given-names>D</given-names></name></person-group><article-title>Participant Partners: College Students Weigh the Costs and Benefits of Deceptive Research</article-title><source>American Psychologist</source><year>1994</year><volume>49</volume><issue>5</issue><fpage>417</fpage><lpage>427</lpage></element-citation></ref><ref id="ref10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wendler</surname><given-names>D</given-names></name><name><surname>Miller</surname><given-names>FG</given-names></name></person-group><article-title>Deception in the pursuit of science</article-title><source>Arch Intern Med</source><year>2004</year><month>3</month><day>22</day><volume>164</volume><issue>6</issue><fpage>597</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1001/archinte.164.6.597</pub-id><pub-id pub-id-type="medline">15037487</pub-id><pub-id pub-id-type="pii">164/6/597</pub-id><pub-id pub-id-type="pmid">15037487</pub-id></element-citation></ref><ref id="ref11"><label>11</label><element-citation publication-type="book"><person-group person-group-type="author"><collab>British Psychological Society</collab></person-group><person-group person-group-type="editor"><name><surname>Eckstein</surname><given-names>S</given-names></name></person-group><article-title>Chapter 42: Ethical principles for conducting research with human participants</article-title><source>Manual for research ethics committees</source><year>2003</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>269</fpage><lpage>273</lpage></element-citation></ref><ref id="ref12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>FG</given-names></name><name><surname>Gluck</surname><given-names>JP</given-names></name><name><surname>Wendler</surname><given-names>D</given-names></name></person-group><article-title>Debriefing and accountability in deceptive research</article-title><source>Kennedy Inst Ethics J</source><year>2008</year><month>9</month><volume>18</volume><issue>3</issue><fpage>235</fpage><lpage>51</lpage><pub-id pub-id-type="medline">18935922</pub-id><pub-id pub-id-type="pmid">18935922</pub-id></element-citation></ref><ref id="ref13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kypri</surname><given-names>K</given-names></name><name><surname>McCambridge</surname><given-names>J</given-names></name><name><surname>Wilson</surname><given-names>A</given-names></name><name><surname>Attia</surname><given-names>J</given-names></name><name><surname>Sheeran</surname><given-names>P</given-names></name><name><surname>Bowe</surname><given-names>S</given-names></name><name><surname>Vater</surname><given-names>T</given-names></name></person-group><article-title>Effects of Study Design and Allocation on participant behaviour--ESDA: study protocol for a randomized controlled trial</article-title><source>Trials</source><year>2011</year><volume>12</volume><issue>1</issue><fpage>42</fpage><comment><ext-link ext-link-type="uri" xlink:href="http://www.trialsjournal.com/content/12/1/42"/></comment><pub-id pub-id-type="doi">10.1186/1745-6215-12-42</pub-id><pub-id pub-id-type="medline">21320316</pub-id><pub-id pub-id-type="pii">1745-6215-12-42</pub-id><pub-id pub-id-type="pmcid">PMC3045904</pub-id><pub-id pub-id-type="pmid">21320316</pub-id></element-citation></ref><ref id="ref14"><label>14</label><element-citation publication-type="webpage"><source>Group A Webpage</source><date-in-citation>2012-11-14</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="http://www.behaviourscience.net/esda_debrief/esda_debrief.html?pid=2402&#x00026;aid=2859">http://www.behaviourscience.net/esda_debrief/esda_debrief.html?pid=2402&#x00026;aid=2859</ext-link></comment><ext-link ext-link-type="webcite" xlink:href="6CAur5MWt"/></element-citation></ref><ref id="ref15"><label>15</label><element-citation publication-type="webpage"><source>Group B Webpage</source><date-in-citation>2012-11-14</date-in-citation><comment><ext-link ext-link-type="uri" xlink:href="http://www.behaviourscience.net/esda_debrief/esda_debrief.html?pid=9917&#x00026;aid=9925">http://www.behaviourscience.net/esda_debrief/esda_debrief.html?pid=9917&#x00026;aid=9925</ext-link></comment><ext-link ext-link-type="webcite" xlink:href="6CAut5pE7"/></element-citation></ref><ref id="ref16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>FG</given-names></name><name><surname>Wendler</surname><given-names>D</given-names></name></person-group><article-title>The relevance of empirical research in bioethics</article-title><source>Schizophr Bull</source><year>2006</year><month>1</month><volume>32</volume><issue>1</issue><fpage>37</fpage><lpage>41</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://schizophreniabulletin.oxfordjournals.org/cgi/pmidlookup?view=long&#x00026;pmid=16192410"/></comment><pub-id pub-id-type="doi">10.1093/schbul/sbj004</pub-id><pub-id pub-id-type="medline">16192410</pub-id><pub-id pub-id-type="pii">sbj004</pub-id><pub-id pub-id-type="pmcid">PMC2632190</pub-id><pub-id pub-id-type="pmid">16192410</pub-id></element-citation></ref></ref-list></back></article>